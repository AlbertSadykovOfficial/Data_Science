"""

		Глубокий анализ текста

				Большая часть информации, сохраняемй людьми, существует в виде текста.
				Компьютеру тяжело работать с такой информацией, для работы с ним существует
				метод глубокого анализа текста.

				Глубокий анализ текста - дисциплина а стыке наук о языке, информатики со статистикой
				и методами машинного обучения.

				Глубокий анализ текста преобразует текст в более структурированную форму и уже
				по этим структурированным данным делается анализ.

				Такой анализ нашел применение в:
					1) Идентификация сущностей
					2) Выявление плагиата
					3) Идентификация темы
					4) Машинный перевод
					5) Фильтры спама

				Классификация текста:
					1) На естественном языке
					2) На искусственном языке (Журналы приложений, математические формулы, Код Морзе)


				Методы глубокого анализа текста:

					Набор слов - способ структурирования информации. При таком способе каждое слово 
					преобразуется в вектор слов. Если слово пристуствует в векторе, ему присваивается True
					Пример:
						Car was blue [('car': True, 'was': True, 'blue': True, 'she': False, 'young': False),
						She was young ('car': False,'was': True, 'blue': False,'she': True,  'young': True)]

					Чтобы получить такой набор слов с текстом происходит много операций обработки:
						1) Генерирование лексем - разбиение текста на лексемы (слова-униграммы, словосочетания-диграммы...)
						2) Фильтрация игнорируемых слов - исключение незначимых слов (предлоги, вводные конструкции, маловстреч. слова)
						3) Преобразование к нижнему регистру - чтобы не усложнять Набор Слов
						4) Выделение основы и лемматизация:
								- Выделение основы - приведение слова к корневой форме (cars-> car, objects->object)
								- Лемматизация - Более осмысленное приведение слова к корневой форме (was -> be, fallen -> fall)
						5) Пометка частей речи (Иногда, чтобы лучше понимать смысл)

						
					Классификация на базе дерева принятия рещений:

						Вспомним принцип работы классификатора Байеса (Machine_Learning->control->classification.py).
						Такой классификатор предполагает, что каждая переменная независима от других.
						В текстовых данных это не так и там много связных данных, поэтому в анализе текста часто
						используются другие классификаторы (при этом классификатор Байеса тоже используется - он неплохо
						себя показывает на небольших объемах данных, где не достаточно данных для построения хороших
						связей)

						Классификатор на базе древа принятия решений старается связать переменные друг с другом, 
						поэтому часто испольхуется для анализа текстовых данных.
						
						Термины:

							Переменная взаимодействия - переменная, объединяющая другие переменные (Мужчина->Возраст->(>25))
							Гнездо - отчасти противоположность - переменная разбивается на несколько переменных  
							(Аналог вершины в бинарном дереве из котрого исходят все другие вершины).

						Энтропия
							Энтропия - мера неопреденности информации. При получении все больших данных энтропия уменьшается
							и мы можем более точно гооврить о достоверности.

							Пример:
								При начальных стадиях береенности можно только гадать кто родится: мальчик или девочка (50/50)- 50% энтр.
								Через 12 недель можно сходить на узи и определить с 90% точностью кто будет, что дает нам уже 10% энтр.

						Количество данных имеет вес.
							Часто при небольшом количестве данных случайные отклонения порождаются ошибочные ветви, которые прнимаются
							за верные данные - за корреляции, чтобы этого не происходило следует учекать дерево принятия решений и
							усекать ветви из итоговой модели, которые не имеют смысла.

						Гепакс

								Гепакс - термин, встречающийся один раз за текст. Одного вхождения мало для модели, поэтому такие данные
								являются избыточными и от них нужно избавляться.

"""